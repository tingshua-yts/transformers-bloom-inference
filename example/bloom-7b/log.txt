[2023-05-31 09:55:42,526] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.9.2, git-hash=unknown, git-branch=unknown
[2023-05-31 09:55:42,526] [INFO] [__init__.py:314:init_inference] AAAA
[2023-05-31 09:55:42,527] [WARNING] [config_utils.py:69:_process_deprecated_field] Config parameter mp_size is deprecated use tensor_parallel.tp_size instead
[2023-05-31 09:55:42,527] [INFO] [logging.py:96:log_dist] [Rank -1] quantize_bits = 8 mlp_extra_grouping = False, quantize_groups = 1
[2023-05-31 09:55:42,531] [INFO] [replace_module.py:294:replace_transformer_layer] AAAAAAAAA
[2023-05-31 09:55:42,531] [INFO] [replace_module.py:501:replace_transformer_layer] AAAAAAAAA
[2023-05-31 09:55:42,537] [INFO] [replace_module.py:735:replace_module] replace_module: <class 'transformers.models.bert.modeling_bert.BertLayer'>
[2023-05-31 09:55:42,537] [INFO] [replace_module.py:735:replace_module] replace_module: <class 'transformers.models.roberta.modeling_roberta.RobertaLayer'>
[2023-05-31 09:55:42,538] [INFO] [replace_module.py:738:replace_module] replace_module: <class 'transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoBlock'>
[2023-05-31 09:55:42,540] [INFO] [replace_module.py:738:replace_module] replace_module: <class 'transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXLayer'>
[2023-05-31 09:55:42,542] [INFO] [replace_module.py:738:replace_module] replace_module: <class 'transformers.models.gptj.modeling_gptj.GPTJBlock'>
[2023-05-31 09:55:42,545] [INFO] [replace_module.py:738:replace_module] replace_module: <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>
[2023-05-31 09:55:42,545] [INFO] [replace_module.py:738:replace_module] replace_module: <class 'transformers.models.bloom.modeling_bloom.BloomBlock'>
[2023-05-31 09:55:42,545] [INFO] [replace_module.py:738:replace_module] replace_module: <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>
[2023-05-31 09:55:42,548] [INFO] [replace_module.py:738:replace_module] replace_module: <class 'transformers.models.clip.modeling_clip.CLIPEncoderLayer'>
[2023-05-31 09:55:42,551] [INFO] [replace_module.py:735:replace_module] replace_module: <class 'transformers.models.distilbert.modeling_distilbert.TransformerBlock'>
[2023-05-31 09:55:42,552] [INFO] [replace_module.py:743:replace_module] model:BloomForCausalLM(
  (transformer): BloomModel(
    (word_embeddings): Embedding(250880, 4096)
    (word_embeddings_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (h): ModuleList(
      (0-29): 30 x BloomBlock(
        (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (self_attention): BloomAttention(
          (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
          (dense): Linear(in_features=4096, out_features=4096, bias=True)
          (attention_dropout): Dropout(p=0.0, inplace=False)
        )
        (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (mlp): BloomMLP(
          (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
          (gelu_impl): BloomGelu()
          (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
        )
      )
    )
    (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  )
  (lm_head): Linear(in_features=4096, out_features=250880, bias=False)
), orig_class:None, policy:{<class 'transformers.models.bert.modeling_bert.BertLayer'>: (<function replace_transformer_layer.<locals>.replace_fn at 0x7fa462abd550>, <class 'deepspeed.module_inject.containers.bert.HFBertLayerPolicy'>), <class 'transformers.models.roberta.modeling_roberta.RobertaLayer'>: (<function replace_transformer_layer.<locals>.replace_fn at 0x7fa462abd550>, <class 'deepspeed.module_inject.containers.bert.HFBertLayerPolicy'>), <class 'transformers.models.gpt_neo.modeling_gpt_neo.GPTNeoBlock'>: (<function replace_transformer_layer.<locals>.replace_fn at 0x7fa462abd550>, <class 'deepspeed.module_inject.containers.gptneo.HFGPTNEOLayerPolicy'>), <class 'transformers.models.gpt_neox.modeling_gpt_neox.GPTNeoXLayer'>: (<function replace_transformer_layer.<locals>.replace_fn at 0x7fa462abd550>, <class 'deepspeed.module_inject.containers.gptneox.GPTNEOXLayerPolicy'>), <class 'transformers.models.gptj.modeling_gptj.GPTJBlock'>: (<function replace_transformer_layer.<locals>.replace_fn at 0x7fa462abd550>, <class 'deepspeed.module_inject.containers.gptj.HFGPTJLayerPolicy'>), <class 'transformers.models.gpt2.modeling_gpt2.GPT2Block'>: (<function replace_transformer_layer.<locals>.replace_fn at 0x7fa462abd550>, <class 'deepspeed.module_inject.containers.gpt2.HFGPT2LayerPolicy'>), <class 'transformers.models.bloom.modeling_bloom.BloomBlock'>: (<function replace_transformer_layer.<locals>.replace_fn at 0x7fa462abd550>, <class 'deepspeed.module_inject.containers.bloom.BLOOMLayerPolicy'>), <class 'transformers.models.opt.modeling_opt.OPTDecoderLayer'>: (<function replace_transformer_layer.<locals>.replace_fn at 0x7fa462abd550>, <class 'deepspeed.module_inject.containers.opt.HFOPTLayerPolicy'>), <class 'transformers.models.clip.modeling_clip.CLIPEncoderLayer'>: (<function replace_transformer_layer.<locals>.replace_fn at 0x7fa462abd550>, <class 'deepspeed.module_inject.containers.clip.HFCLIPLayerPolicy'>), <class 'transformers.models.distilbert.modeling_distilbert.TransformerBlock'>: (<function replace_transformer_layer.<locals>.replace_fn at 0x7fa462abd550>, <class 'deepspeed.module_inject.containers.distil_bert.HFDistilBertLayerPolicy'>)}
[2023-05-31 09:55:42,552] [INFO] [replace_module.py:759:_replace_module] layer_id:0
[2023-05-31 09:55:42,553] [INFO] [replace_module.py:761:_replace_module] name:transformer, child:BloomModel(
  (word_embeddings): Embedding(250880, 4096)
  (word_embeddings_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (h): ModuleList(
    (0-29): 30 x BloomBlock(
      (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
      (self_attention): BloomAttention(
        (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
        (dense): Linear(in_features=4096, out_features=4096, bias=True)
        (attention_dropout): Dropout(p=0.0, inplace=False)
      )
      (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
      (mlp): BloomMLP(
        (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
        (gelu_impl): BloomGelu()
        (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
      )
    )
  )
  (ln_f): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
)
[2023-05-31 09:55:42,553] [INFO] [replace_module.py:759:_replace_module] layer_id:0
[2023-05-31 09:55:42,553] [INFO] [replace_module.py:761:_replace_module] name:word_embeddings, child:Embedding(250880, 4096)
[2023-05-31 09:55:42,553] [INFO] [replace_module.py:759:_replace_module] layer_id:0
[2023-05-31 09:55:42,553] [INFO] [replace_module.py:761:_replace_module] name:word_embeddings_layernorm, child:LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
[2023-05-31 09:55:42,553] [INFO] [replace_module.py:759:_replace_module] layer_id:0
[2023-05-31 09:55:42,554] [INFO] [replace_module.py:761:_replace_module] name:h, child:ModuleList(
  (0-29): 30 x BloomBlock(
    (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (self_attention): BloomAttention(
      (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
      (dense): Linear(in_features=4096, out_features=4096, bias=True)
      (attention_dropout): Dropout(p=0.0, inplace=False)
    )
    (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
    (mlp): BloomMLP(
      (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
      (gelu_impl): BloomGelu()
      (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
    )
  )
)
[2023-05-31 09:55:42,554] [INFO] [replace_module.py:759:_replace_module] layer_id:0
[2023-05-31 09:55:42,554] [INFO] [replace_module.py:761:_replace_module] name:0, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:42,555] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:42,555] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
ninja: no work to do.
Time to load transformer_inference op: 0.1478745937347412 seconds
[2023-05-31 09:55:43,669] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed-Inference config: {'layer_id': 0, 'hidden_size': 4096, 'intermediate_size': 16384, 'heads': 32, 'num_hidden_layers': -1, 'fp16': True, 'pre_layer_norm': True, 'local_rank': -1, 'stochastic_mode': False, 'epsilon': 1e-05, 'mp_size': 1, 'q_int8': False, 'scale_attention': True, 'triangular_masking': True, 'local_attention': False, 'window_size': 1, 'rotary_dim': -1, 'rotate_half': False, 'rotate_every_two': True, 'return_tuple': True, 'mlp_after_attn': True, 'mlp_act_func_type': <ActivationFuncType.GELU: 1>, 'specialized_mode': False, 'training_mp_size': 1, 'bigscience_bloom': True, 'max_out_tokens': 1024, 'min_out_tokens': 1, 'scale_attn_by_inverse_layer_idx': False, 'enable_qkv_quantization': False, 'use_mup': False, 'return_single_tuple': False, 'set_empty_params': False, 'transposed_mode': False}
Time to load transformer_inference op: 0.015308856964111328 seconds
[2023-05-31 09:55:43,860] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,861] [INFO] [replace_module.py:761:_replace_module] name:1, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,861] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,861] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,864] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,864] [INFO] [replace_module.py:761:_replace_module] name:2, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,864] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,864] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,867] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,867] [INFO] [replace_module.py:761:_replace_module] name:3, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,867] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,867] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,869] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,869] [INFO] [replace_module.py:761:_replace_module] name:4, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,869] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,869] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,872] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,872] [INFO] [replace_module.py:761:_replace_module] name:5, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,872] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,872] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,875] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,875] [INFO] [replace_module.py:761:_replace_module] name:6, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,875] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,875] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,877] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,877] [INFO] [replace_module.py:761:_replace_module] name:7, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,877] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,877] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,880] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,880] [INFO] [replace_module.py:761:_replace_module] name:8, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,880] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,880] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,882] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,883] [INFO] [replace_module.py:761:_replace_module] name:9, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,883] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,883] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,885] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,885] [INFO] [replace_module.py:761:_replace_module] name:10, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,885] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,885] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,888] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,888] [INFO] [replace_module.py:761:_replace_module] name:11, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,888] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,888] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,890] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,890] [INFO] [replace_module.py:761:_replace_module] name:12, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,890] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,890] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,893] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,893] [INFO] [replace_module.py:761:_replace_module] name:13, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,893] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,893] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,895] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,895] [INFO] [replace_module.py:761:_replace_module] name:14, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,895] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,895] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,898] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,898] [INFO] [replace_module.py:761:_replace_module] name:15, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,898] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,898] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,900] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,901] [INFO] [replace_module.py:761:_replace_module] name:16, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,901] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,901] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,903] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,903] [INFO] [replace_module.py:761:_replace_module] name:17, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,903] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,903] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,905] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,906] [INFO] [replace_module.py:761:_replace_module] name:18, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,906] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,906] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,908] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,908] [INFO] [replace_module.py:761:_replace_module] name:19, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,908] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,908] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,911] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,911] [INFO] [replace_module.py:761:_replace_module] name:20, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,911] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,911] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,913] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,914] [INFO] [replace_module.py:761:_replace_module] name:21, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,914] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,914] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,916] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,916] [INFO] [replace_module.py:761:_replace_module] name:22, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,916] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,916] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,919] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,919] [INFO] [replace_module.py:761:_replace_module] name:23, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,919] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,919] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,921] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,921] [INFO] [replace_module.py:761:_replace_module] name:24, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,921] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,922] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,924] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,924] [INFO] [replace_module.py:761:_replace_module] name:25, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,924] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,924] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,926] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,927] [INFO] [replace_module.py:761:_replace_module] name:26, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,927] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,927] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,929] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,929] [INFO] [replace_module.py:761:_replace_module] name:27, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,929] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,929] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,932] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,932] [INFO] [replace_module.py:761:_replace_module] name:28, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,932] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,932] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,934] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,934] [INFO] [replace_module.py:761:_replace_module] name:29, child:BloomBlock(
  (input_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (self_attention): BloomAttention(
    (query_key_value): Linear(in_features=4096, out_features=12288, bias=True)
    (dense): Linear(in_features=4096, out_features=4096, bias=True)
    (attention_dropout): Dropout(p=0.0, inplace=False)
  )
  (post_attention_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
  (mlp): BloomMLP(
    (dense_h_to_4h): Linear(in_features=4096, out_features=16384, bias=True)
    (gelu_impl): BloomGelu()
    (dense_4h_to_h): Linear(in_features=16384, out_features=4096, bias=True)
  )
)
[2023-05-31 09:55:43,934] [INFO] [replace_module.py:482:replace_fn] AAAAAAAAA
[2023-05-31 09:55:43,934] [INFO] [replace_module.py:308:replace_with_policy] replace_with_policy
[2023-05-31 09:55:43,937] [INFO] [replace_module.py:765:_replace_module] <class 'transformers.models.bloom.modeling_bloom.BloomBlock'> in policies execute replace with DeepSpeedBloomInference(
  (attention): BloomSelfAttention(
    (qkv_func): QKVGemmOp()
    (score_context_func): SoftmaxContextOp()
    (linear_func): LinearOp()
    (vector_matmul_func): VectorMatMulOp()
    (softmax_func): SoftmaxOp()
  )
  (mlp): DeepSpeedMLP(
    (mlp_gemm_func): MLPGemmOp()
    (vector_matmul_func): VectorMatMulOp()
    (fused_gemm_gelu): GELUGemmOp()
    (residual_add_func): ResidualAddOp()
  )
)
[2023-05-31 09:55:43,938] [INFO] [replace_module.py:761:_replace_module] name:ln_f, child:LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
[2023-05-31 09:55:43,938] [INFO] [replace_module.py:759:_replace_module] layer_id:30
[2023-05-31 09:55:43,938] [INFO] [replace_module.py:761:_replace_module] name:lm_head, child:Linear(in_features=4096, out_features=250880, bias=False)
[2023-05-31 09:55:43,938] [INFO] [replace_module.py:759:_replace_module] layer_id:30
[2023-05-31 09:55:43,939] [INFO] [replace_module.py:510:replace_transformer_layer] AAAAAAAAA: checkpoint_dict:{'type': 'BLOOM', 'version': 1.0, 'checkpoints': ['/mnt/model/bloom-7b1/pytorch_model-00001-of-00002.bin', '/mnt/model/bloom-7b1/pytorch_model-00002-of-00002.bin']}
[2023-05-31 09:55:43,939] [INFO] [replace_module.py:512:replace_transformer_layer] bbbbbbbbb
[2023-05-31 09:55:47,952] [INFO] [load_checkpoint.py:29:load_model_with_checkpoint] load_model_with_checkpoint
[2023-05-31 09:55:47,953] [INFO] [load_checkpoint.py:247:load_model_with_checkpoint] before load_module_recursive
[2023-05-31 09:55:47,953] [INFO] [load_checkpoint.py:204:load_module_recursive] load_module_recursive, module: <class 'transformers.models.bloom.modeling_bloom.BloomForCausalLM'>, prefix: , level: 
[2023-05-31 09:55:47,953] [INFO] [load_checkpoint.py:204:load_module_recursive] load_module_recursive, module: <class 'transformers.models.bloom.modeling_bloom.BloomModel'>, prefix: , level: 
[2023-05-31 09:55:47,956] [INFO] [load_checkpoint.py:50:load] load_no_transformer_layer , module:<class 'deepspeed.module_inject.layers.EmbeddingLayer'>, prefix:word_embeddings.
[2023-05-31 09:55:49,430] [INFO] [load_checkpoint.py:50:load] load_no_transformer_layer , module:<class 'deepspeed.module_inject.layers.Normalize'>, prefix:word_embeddings_layernorm.
[2023-05-31 09:55:49,534] [INFO] [load_checkpoint.py:204:load_module_recursive] load_module_recursive, module: <class 'torch.nn.modules.container.ModuleList'>, prefix: h., level: h.
[2023-05-31 09:55:49,534] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.0., ckpt_type:pp
[2023-05-31 09:55:50,039] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.1., ckpt_type:pp
[2023-05-31 09:55:50,542] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.2., ckpt_type:pp
[2023-05-31 09:55:51,044] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.3., ckpt_type:pp
[2023-05-31 09:55:51,544] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.4., ckpt_type:pp
[2023-05-31 09:55:52,044] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.5., ckpt_type:pp
[2023-05-31 09:55:52,545] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.6., ckpt_type:pp
[2023-05-31 09:55:53,044] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.7., ckpt_type:pp
[2023-05-31 09:55:53,544] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.8., ckpt_type:pp
[2023-05-31 09:55:54,060] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.9., ckpt_type:pp
[2023-05-31 09:55:54,564] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.10., ckpt_type:pp
[2023-05-31 09:55:55,063] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.11., ckpt_type:pp
[2023-05-31 09:55:55,562] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.12., ckpt_type:pp
[2023-05-31 09:55:56,061] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.13., ckpt_type:pp
[2023-05-31 09:55:56,561] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.14., ckpt_type:pp
[2023-05-31 09:55:57,061] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.15., ckpt_type:pp
[2023-05-31 09:55:57,559] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.16., ckpt_type:pp
[2023-05-31 09:55:58,058] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.17., ckpt_type:pp
[2023-05-31 09:55:58,557] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.18., ckpt_type:pp
[2023-05-31 09:55:59,057] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.19., ckpt_type:pp
[2023-05-31 09:55:59,394] [INFO] [load_checkpoint.py:249:load_model_with_checkpoint] after load_module_recursive
[2023-05-31 09:56:01,216] [INFO] [load_checkpoint.py:29:load_model_with_checkpoint] load_model_with_checkpoint
[2023-05-31 09:56:01,216] [INFO] [load_checkpoint.py:247:load_model_with_checkpoint] before load_module_recursive
[2023-05-31 09:56:01,216] [INFO] [load_checkpoint.py:204:load_module_recursive] load_module_recursive, module: <class 'transformers.models.bloom.modeling_bloom.BloomForCausalLM'>, prefix: , level: 
[2023-05-31 09:56:01,216] [INFO] [load_checkpoint.py:204:load_module_recursive] load_module_recursive, module: <class 'transformers.models.bloom.modeling_bloom.BloomModel'>, prefix: , level: 
[2023-05-31 09:56:01,216] [INFO] [load_checkpoint.py:204:load_module_recursive] load_module_recursive, module: <class 'torch.nn.modules.container.ModuleList'>, prefix: h., level: h.
[2023-05-31 09:56:01,217] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.19., ckpt_type:pp
[2023-05-31 09:56:01,383] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.20., ckpt_type:pp
[2023-05-31 09:56:01,883] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.21., ckpt_type:pp
[2023-05-31 09:56:02,383] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.22., ckpt_type:pp
[2023-05-31 09:56:02,882] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.23., ckpt_type:pp
[2023-05-31 09:56:03,381] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.24., ckpt_type:pp
[2023-05-31 09:56:03,880] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.25., ckpt_type:pp
[2023-05-31 09:56:04,379] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.26., ckpt_type:pp
[2023-05-31 09:56:04,878] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.27., ckpt_type:pp
[2023-05-31 09:56:05,378] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.28., ckpt_type:pp
[2023-05-31 09:56:05,877] [INFO] [load_checkpoint.py:65:load_transformer_layer] load_transformer_layer , module:<class 'deepspeed.model_implementations.transformers.ds_bloom.DeepSpeedBloomInference'>, prefix:h.29., ckpt_type:pp
[2023-05-31 09:56:06,377] [INFO] [load_checkpoint.py:50:load] load_no_transformer_layer , module:<class 'deepspeed.module_inject.layers.Normalize'>, prefix:ln_f.
[2023-05-31 09:56:06,509] [INFO] [load_checkpoint.py:249:load_model_with_checkpoint] after load_module_recursive
checkpoint loading time at rank 0: 22.67586398124695 sec
[2023-05-31 09:56:06,615] [INFO] [replace_module.py:583:replace_transformer_layer] AAAAAAAAA config.save_mp_checkpoint_path: None
------------------------------------------------------
Free memory : 1.128662 (GigaBytes)  
Total memory: 14.755615 (GigaBytes)  
Requested memory: 0.140625 (GigaBytes) 
Setting maximum total tokens (input + output) to 1024 
WorkSpace: 0x7f9d0c000000 
------------------------------------------------------
naive result: deepspeed is the speed of the ship at the time of the collision, and the
de
